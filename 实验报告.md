# 项目2实验报告
刘辰昕 2021010448 
该代码上传至github，地址为https://github.com/starsoul-ss/cnn_project

## 任务实现
1. **基本任务**：
- 设计一个由三个卷积层、三个池化层、两个全连接层构成的卷积神经网络
- 采用Pytorch实现模型，其中版本为
```
python = 3.11.9
pytorch = 2.3.0
CUDA = 12.1 
cuDNN = 8.9.02
```
- 采用混淆矩阵对模型的分类效果进行评估，混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。每一列中的数值表示真实数据被预测为该类的数目。
实验结果如下：
```
 [436   4   9   6  22  71]
 [  9 514   1   7   0  19]
 [ 13   3 449  60  65   9]
 [  7   3  72 451  56   5]
 [  7   0  31  30 475  11]
 [ 79   7   5   3   8 460]
```
- 实现以上设计，实验结果保存至`doc.md`
- 采用精确率、召回率、F1分数对模型的效果进行评估.
其中**精确率**指的是预测为正类中，实际上为正类的比例。对于一个类别来说，精确率的计算公式是：
$Precision=\frac{TP}{TP + FP}$
这表示预测为该类别且正确的结果占所有预测为该类别的结果的比例。
**召回率**指的是所有实际为正类的样本中，被正确预测为正类的比例，计算公式为：
$Recall=\frac{TP}{TP+FN}$
**F1分数**指的是精确率和召回率的调和平均数，计算公式为：
$F_1 = \frac{2*Precision*Recall}{Precision+Recall}$
- 实验中数据计算得到：
$Precision = 0.82$  
$Recall = 0.82$  
$F_1 = 0.82$  
2. **改进模型**
采用输入数据处理、调整合适超参数、更改模型结构三种方法对模型进行优化，记录如下：
- 更改超参数：
```
#更改学习率从0.001为0.005，过拟合
Train Loss: 0.7559, Validation Loss: 0.7788, Validation Accuracy: 0.7172
#更改epoch为4，学习能力较好
Train Loss: 0.2636, Validation Loss: 0.5098, Validation Accuracy: 0.8302
Test Loss: 0.5410, Test Accuracy: 0.8207
#初始lr0.004，变学习率，每次改为之前的0.5倍，学习率有调整，但还是出现过拟合的情况
Train Loss: 0.1017, Validation Loss: 1.2559, Validation Accuracy: 0.7671
#初始lr0.01，变学习率，每次改为0.1倍，有调整，但拟合效果很差
Train Loss: 1.7906, Validation Loss: 1.7923, Validation Accuracy: 0.1739

最终选择变学习率，从0.001开始，早停patience为4，训练25个epoch
```
- 输入数据处理：
```
#没有按照imagenet的数据集参数进行归一化，模型效果反而更好
Train Loss: 0.0810, Validation Loss: 0.5688, Validation Accuracy: 0.8379
Test Loss: 0.5747, Test Accuracy: 0.8397
#采用图片预处理，增加了随机水平翻转与随机旋转正负15度，模型的学习效果更好
Train Loss: 0.1840, Validation Loss: 0.4290, Validation Accuracy: 0.8668
Test Loss: 0.4466, Test Accuracy: 0.8579

最终选择图片预处理时，增加水平随机翻转、随机旋转15度、正则化
```
- 模型结构改进：
```
#增加dropout在每个卷积层后和两个全连接层之间，共四个。与上一个模型效果相差不大，可能是数据预处理带来的数据增强让额外的正则化不会产生太大影响
Train Loss: 0.3745, Validation Loss: 0.4421, Validation Accuracy: 0.8401
Test Loss: 0.4457, Test Accuracy: 0.8453
#将卷积层之后的dropout删除，只保留全连接层之间的dropout，效果有改进
Train Loss: 0.2307, Validation Loss: 0.4013, Validation Accuracy: 0.8712
Test Loss: 0.3903, Test Accuracy: 0.8694

最终选择只在两个全连接层之间增加dropout层，概率为0.5
```
3. **模型的可解释化**
- 可视化方法：采用Grad-CAM对模型决策过程进行解释
1. 图6897，label=0
  <p float="left">
    <img src="/cam/Figure_6897-cam.png" width="200" />
    <img src="/data/imgs/6897.jpg" width="200" /> 
  </p>
1. 图757，label=1
  <p float="left">
    <img src="/cam/Figure_757-cam.png" width="200" />
    <img src="/data/imgs/757.jpg" width="200" /> 
  </p>
1. 图5319，label=2
  <p float="left">
    <img src="/cam/Figure_5319-cam.png" width="200" />
    <img src="/data/imgs/5319.jpg" width="200" /> 
  </p>
2. 图395，label=3
  <p float="left">
    <img src="/cam/Figure_395-cam.png" width="200" />
    <img src="/data/imgs/395.jpg" width="200" /> 
  </p>
1. 图200，label=4
  <p float="left">
    <img src="/cam/Figure_200-cam.png" width="200" />
    <img src="/data/imgs/200.jpg" width="200" /> 
  </p>
1. 图16175，label=5
  <p float="left">
    <img src="/cam/Figure_16175-cam.png" width="200" />
    <img src="/data/imgs/16175.jpg" width="200" /> 
  </p>

- 不同类别分类的促进：
去除一类样本后重新训练模型，重新评估和测试，模型的准确率有很明显的提升，随着去掉的类别越来越多，模型的准确率越来越高
```
#去掉label=5的样本，五分类问题
Train Loss: 0.1526, Validation Loss: 0.3474, Validation Accuracy: 0.8920
Test Loss: 0.3545, Test Accuracy: 0.8949
precision=recall=0.90

#去掉label=4，5的样本，四分类问题
Train Loss: 0.2135, Validation Loss: 0.2475, Validation Accuracy: 0.9132
Test Loss: 0.2539, Test Accuracy: 0.9031
precision=recall=0.91

#去掉label=3，4，5的样本，三分类问题
Train Loss: 0.0600, Validation Loss: 0.1021, Validation Accuracy: 0.9651
Test Loss: 0.1254, Test Accuracy: 0.9641
precision=recall=0.96

#去掉label=2，3，4，5的样本，二分类问题
Train Loss: 0.0429, Validation Loss: 0.0713, Validation Accuracy: 0.9775
Test Loss: 0.0571, Test Accuracy: 0.9763
precision=recall=0.98

```

## 实验讨论
- 调试遇到的问题包括训练时过拟合；添加变学习率后效果不明显。后来增加早停，调整早停patience与变学习率调整的patience之间的关系，保证变学习率起作用。硬件上的问题包括显卡驱动与CUDA版本不对应；pytorch与CUDA版本不对应等，后来重装整个环境后解决这一问题。
- 该问题是一个经典的CNN多分类问题，推荐可以在项目2各类任务的描述下给出比较经典的paper参考，可以在做完这个项目意犹未尽的时候知道具体可以干什么，学界又发展到了哪个阶段。